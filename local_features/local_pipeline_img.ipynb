{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9227b497",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import patch_extraction as ext\n",
    "import VAE\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from VAE.models.vanilla_vae import VanillaVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f69ee3f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def gram_matrix(tensor):\n",
    "    b, c, h, w = tensor.size()\n",
    "    features = tensor.view(b, c, h * w)  # [B, C, H*W]\n",
    "    G = torch.bmm(features, features.transpose(1, 2))  # [B, C, C]\n",
    "    return G / (c * h * w)  # Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850fe181",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def extract_patch(image):\n",
    "\n",
    "    # Compute scores\n",
    "    patch_scores = ext.compute_gradient_scores(image, patch_size=64, stride=64//2)\n",
    "\n",
    "    # Keep top 10%\n",
    "    n_top = int(len(patch_scores)*0.90)\n",
    "    top_patches = ext.get_top_patches(patch_scores, top_k=n_top)\n",
    "\n",
    "    # Extract patches\n",
    "    return ext.extract_patches_array_with_dog(image, top_patches, \n",
    "                                                          34, top_k=5, apply_dog_to_patches=True,\n",
    "                                                          dog_sigma1= 1.0, dog_sigma2=2.0)\n",
    "#on modifiera cette méthode pour obtenir des patchs aléatoirement plutôt que prendre les 5 meilleurs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef979ecb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    " vae_model = VanillaVAE(in_channels=1, latent_dim=64, kld_weight=1e-3).to(device)\n",
    "    checkpoint = torch.load(\".\\vae_checkpoint_epoch4_batch44345.pt\", map_location=torch.device('cuda'))  # ou 'cuda' si tu es sur GPU\n",
    "    vae_model.load_state_dict(checkpoint)\n",
    "    vae_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172b65ab",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "data_path = \n",
    "with torch.no_grad :\n",
    "    #Extraction des patchs de l'image\n",
    "    image = cv2.imread(data_path)\n",
    "    if image is None:\n",
    "        return print(f\"Could not read image: {data_path}\") \n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    selected_patches = extract_patch(image)\n",
    "    ext.visualize_patches(image, patch_scores, patch_size=64, top_k=5)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
